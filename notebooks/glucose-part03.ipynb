{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7d9813-563a-43c1-89c8-8373f72578cb",
   "metadata": {},
   "source": [
    "# Planning and prepping for next steps\n",
    "\n",
    "I'm still not 100% sure where this will end up but I'm starting by visualizing the data in as many ways as I can. I was thinking through this process and made some notes on possible visualizations, and also just lists of dependent and independent variables I could look at. \n",
    "\n",
    "><div>\n",
    "<img src=\"../assets/images/variables-notes-sm.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Some of these are easier to extract than others. Of course plain CGM data is probably the easiest but daily CGM histograms won't be too bad either. I don't even record pre-bolus time so that's not happening any time soon. Even if I started now I wouldn't have enough data to do anything meaningful for a while. And as far as I know there's not a really easy way to record pre-bolus time.\n",
    "\n",
    "I also made some sketches of possible visualizations that I could put together:\n",
    "\n",
    "><div>\n",
    "<img src=\"../assets/images/plot-ideas-sm.jpg\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156840d-3c3f-4528-9e54-7e418278e3ba",
   "metadata": {},
   "source": [
    "## Prep data\n",
    "\n",
    "Most of what I need to make the plots in the figure above is not available yet. In the rest of this notebook I'm going to work on extracting what I will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6863c7e8-9b55-4b9a-b6c4-4569afdb0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# since this notebook lives in a sub-folder of the main project, I'll add the main folder to the python path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Load my module\n",
    "from tools.glooko import read_all\n",
    "\n",
    "# Load extra stuff that I need\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# Plotting (matplotlib widge allows for interactivity in the live notebook)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0694b283-210b-494a-aa28-58d887a4bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "df_cgm, df_bolus, df_basal, df_insulin = read_all(r\"../data\")\n",
    "\n",
    "# Extract carb correction and insulin correction from bolus dataframe; add as new columns (I think I want these \n",
    "# split out, but I'm not sure. If it works out I may add to my glooko module. \n",
    "df_bolus[\"carb_correction\"] = np.divide(df_bolus[\"carbs_input\"], df_bolus[\"carb_ratio\"])\n",
    "df_bolus[\"insulin_correction\"] = df_bolus[\"insulin_delivered\"] - df_bolus[\"carb_correction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50e938-2330-4e2c-8c70-5218c690ab9a",
   "metadata": {},
   "source": [
    "## Get Unique Days\n",
    "\n",
    "Since the plots I planned above all have date along the x axis, I'll need to split out the data by unique day. At this point I have only 2023 data, so technically year is not needed, but just in case I end up looking at data that spans two (or more???) years, I'll construct a column for \"year-day\". So it will look like \"2023-018\" for January 18th, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef05c472-226f-4698-9129-cf4085ddded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-018' '2023-019' '2023-020' '2023-021' '2023-022' '2023-023'\n",
      " '2023-024' '2023-025' '2023-026' '2023-027' '2023-028' '2023-029'\n",
      " '2023-030' '2023-031' '2023-032' '2023-033' '2023-034' '2023-035'\n",
      " '2023-036' '2023-037' '2023-038' '2023-039' '2023-040' '2023-041'\n",
      " '2023-042' '2023-043' '2023-044' '2023-045' '2023-046']\n"
     ]
    }
   ],
   "source": [
    "df_cgm[\"dayofyear\"] = df_cgm[\"time\"].dt.dayofyear\n",
    "df_cgm[\"year\"] = df_cgm[\"time\"].dt.year\n",
    "df_cgm[\"yearday\"] = df_cgm[\"year\"].astype(str) + '-' + df_cgm[\"dayofyear\"].map('{:03.0f}'.format)\n",
    "\n",
    "# Print a list of the unique day being analyzed\n",
    "print(np.unique(df_cgm[\"yearday\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f375e-4957-43d8-9bdd-dc9118fb816e",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0847a468-f1d8-4a10-9e02-0906652e5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up histogram bins\n",
    "bin_width = 10 # units - mg/dL\n",
    "bin_min = 50\n",
    "bin_max = 400\n",
    "bin_edges = np.arange(bin_min, bin_max+1, bin_width)\n",
    "\n",
    "# Loop through dates and compute BG histogram for each day\n",
    "bg_histo_arr = [] # initialize a list to hold the histogram array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84353610-4e89-45b9-98b7-890add60aaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
